{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063c7c0a",
   "metadata": {},
   "source": [
    "## parquet paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b58e846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107782 - The Piraeus AIS Dataset for Large-Scale Maritime Data Analytics.pdf\n",
      "ais_augmented.parquet\n",
      "ais_cleaned.parquet\n",
      "ais_loiter.parquet\n",
      "ais_loiter_pair.parquet\n",
      "ais_static\n",
      "geodata\n",
      "models\n",
      "noaa_weather\n",
      "parquet\n",
      "processed\n",
      "sar\n",
      "unipi_ais_dynamic_2017\n",
      "unipi_ais_dynamic_2018\n",
      "unipi_ais_dynamic_2019\n",
      "unipi_ais_dynamic_synopses\n"
     ]
    }
   ],
   "source": [
    "!ls ../dataset/piraeus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca60ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "unipi_ais_dynamic_aug2017.csv\n",
      "unipi_ais_dynamic_dec2017.csv\n",
      "unipi_ais_dynamic_jul2017.csv\n",
      "unipi_ais_dynamic_jun2017.csv\n",
      "unipi_ais_dynamic_may2017.csv\n",
      "unipi_ais_dynamic_nov2017.csv\n",
      "unipi_ais_dynamic_oct2017.csv\n",
      "unipi_ais_dynamic_sep2017.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../dataset/piraeus/unipi_ais_dynamic_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec9b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "unipi_ais_dynamic_apr2018.csv\n",
      "unipi_ais_dynamic_aug2018.csv\n",
      "unipi_ais_dynamic_dec2018.csv\n",
      "unipi_ais_dynamic_feb2018.csv\n",
      "unipi_ais_dynamic_jan2018.csv\n",
      "unipi_ais_dynamic_jul2018.csv\n",
      "unipi_ais_dynamic_jun2018.csv\n",
      "unipi_ais_dynamic_mar2018.csv\n",
      "unipi_ais_dynamic_may2018.csv\n",
      "unipi_ais_dynamic_nov2018.csv\n",
      "unipi_ais_dynamic_oct2018.csv\n",
      "unipi_ais_dynamic_sep2018.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../dataset/piraeus/unipi_ais_dynamic_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93347c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "unipi_ais_dynamic_apr2019.csv\n",
      "unipi_ais_dynamic_aug2019.csv\n",
      "unipi_ais_dynamic_dec2019.csv\n",
      "unipi_ais_dynamic_feb2019.csv\n",
      "unipi_ais_dynamic_jan2019.csv\n",
      "unipi_ais_dynamic_jul2019.csv\n",
      "unipi_ais_dynamic_jun2019.csv\n",
      "unipi_ais_dynamic_mar2019.csv\n",
      "unipi_ais_dynamic_may2019.csv\n",
      "unipi_ais_dynamic_nov2019.csv\n",
      "unipi_ais_dynamic_oct2019.csv\n",
      "unipi_ais_dynamic_sep2019.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../dataset/piraeus/unipi_ais_dynamic_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "672b6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.3\n",
      "23.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas, pyarrow\n",
    "print(pandas.__version__)\n",
    "print(pyarrow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85d32f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t                                                1494345047000\n",
      "vessel_id    b0b2bd45bbb8911fbea20744b0e8b98bbb0e76f6c3af37...\n",
      "lat                                                  37.929298\n",
      "lon                                                  23.682772\n",
      "heading                                                   30.0\n",
      "speed                                                      0.0\n",
      "course                                                   170.0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "pq_file = pq.ParquetFile(\"unipi_ais_dynamic_may2017.parquet\")\n",
    "\n",
    "# Suppose row groups are ~500k rows each\n",
    "row_group_index = 6  # 6*500k = 3Mth row\n",
    "table = pq_file.read_row_group(row_group_index)\n",
    "\n",
    "df_chunk = table.to_pandas()  # Only this row group in memory\n",
    "row = df_chunk.iloc[0]  # Approx 3Mth row\n",
    "print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eebefe",
   "metadata": {},
   "source": [
    "## Random Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ef42d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('64bit', 'WindowsPE')\n",
      "3.10.19 | packaged by conda-forge | (main, Jan 26 2026, 23:39:36) [MSC v.1944 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.architecture()); import sys; print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961d9b5",
   "metadata": {},
   "source": [
    "# Clustering based on TRACLUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273af2d",
   "metadata": {},
   "source": [
    "## Core data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7b466fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Point:\n",
    "    \"\"\"\n",
    "    AIS point.\n",
    "    \"\"\"\n",
    "    x: float\n",
    "    y: float\n",
    "    t: int\n",
    "\n",
    "@dataclass\n",
    "class Segment:\n",
    "    \"\"\"\n",
    "    Line segment between two points.\n",
    "    \"\"\"\n",
    "    p1: Point\n",
    "    p2: Point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c81ed",
   "metadata": {},
   "source": [
    "## Trajectory construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc1f21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trajectories(df):\n",
    "    \"\"\"\n",
    "    Group AIS points into trajectories.\n",
    "    \"\"\"\n",
    "    trajectories = {}\n",
    "    for vid, g in df.groupby(\"vessel_id\"):\n",
    "        g = g.sort_values(\"t\")\n",
    "        pts = [Point(r.lon, r.lat, r.t) for r in g.itertuples()]\n",
    "        if len(pts) >= 2:\n",
    "            trajectories[vid] = pts\n",
    "    return trajectories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1373287",
   "metadata": {},
   "source": [
    "## MDL-based trajectory partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c67761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdl_cost(points, i, j):\n",
    "    \"\"\"\n",
    "    MDL cost between points i and j.\n",
    "    \"\"\"\n",
    "    pi, pj = points[i], points[j]\n",
    "    length = np.hypot(pj.x - pi.x, pj.y - pi.y)\n",
    "    return np.log2(length + 1e-9)\n",
    "\n",
    "def partition_trajectory(points):\n",
    "    \"\"\"\n",
    "    Partition trajectory using MDL principle.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    start = 0\n",
    "    for i in range(2, len(points)):\n",
    "        cost_no_split = mdl_cost(points, start, i)\n",
    "        cost_split = mdl_cost(points, start, i - 1) + mdl_cost(points, i - 1, i)\n",
    "        if cost_split < cost_no_split:\n",
    "            segments.append(Segment(points[start], points[i - 1]))\n",
    "            start = i - 1\n",
    "    segments.append(Segment(points[start], points[-1]))\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add073a5",
   "metadata": {},
   "source": [
    "## Segment distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d99e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_distance(s1, s2):\n",
    "    \"\"\"\n",
    "    TRACLUS distance: perpendicular + parallel + angular.\n",
    "    \"\"\"\n",
    "    def vec(s):\n",
    "        return np.array([s.p2.x - s.p1.x, s.p2.y - s.p1.y])\n",
    "\n",
    "    v1, v2 = vec(s1), vec(s2)\n",
    "    ang = np.arccos(\n",
    "        np.clip(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)), -1, 1)\n",
    "    )\n",
    "\n",
    "    mid1 = np.array([(s1.p1.x + s1.p2.x) / 2, (s1.p1.y + s1.p2.y) / 2])\n",
    "    mid2 = np.array([(s2.p1.x + s2.p2.x) / 2, (s2.p1.y + s2.p2.y) / 2])\n",
    "\n",
    "    return np.linalg.norm(mid1 - mid2) + ang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256380a4",
   "metadata": {},
   "source": [
    "## Line-segment clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3181eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_segments(segments, eps, min_samples):\n",
    "    \"\"\"\n",
    "    DBSCAN-style clustering for line segments.\n",
    "    \"\"\"\n",
    "    labels = [-1] * len(segments)\n",
    "    cid = 0\n",
    "\n",
    "    for i, s in enumerate(segments):\n",
    "        if labels[i] != -1:\n",
    "            continue\n",
    "        neighbors = [\n",
    "            j for j, s2 in enumerate(segments)\n",
    "            if segment_distance(s, s2) < eps\n",
    "        ]\n",
    "        if len(neighbors) < min_samples:\n",
    "            continue\n",
    "\n",
    "        for j in neighbors:\n",
    "            labels[j] = cid\n",
    "        cid += 1\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c178c5",
   "metadata": {},
   "source": [
    "# Collecting segments from a chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7de71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments(df):\n",
    "    \"\"\"\n",
    "    Build and partition trajectories into line segments.\n",
    "    \"\"\"\n",
    "    trajectories = build_trajectories(df)\n",
    "    segments = []\n",
    "    for pts in trajectories.values():\n",
    "        segments.extend(partition_trajectory(pts))\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba2aff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BBBS-AI-01\\AppData\\Local\\Temp\\ipykernel_28640\\1318854926.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.clip(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)), -1, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m segments \u001b[38;5;241m=\u001b[39m extract_segments(df_chunk)\n\u001b[1;32m----> 3\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_segments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 11\u001b[0m, in \u001b[0;36mcluster_segments\u001b[1;34m(segments, eps, min_samples)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels[i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m neighbors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     j \u001b[38;5;28;01mfor\u001b[39;00m j, s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(segments)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m segment_distance(s, s2) \u001b[38;5;241m<\u001b[39m eps\n\u001b[0;32m     14\u001b[0m ]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(neighbors) \u001b[38;5;241m<\u001b[39m min_samples:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels[i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     11\u001b[0m neighbors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     j \u001b[38;5;28;01mfor\u001b[39;00m j, s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(segments)\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msegment_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m eps\n\u001b[0;32m     14\u001b[0m ]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(neighbors) \u001b[38;5;241m<\u001b[39m min_samples:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m, in \u001b[0;36msegment_distance\u001b[1;34m(s1, s2)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([s\u001b[38;5;241m.\u001b[39mp2\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m-\u001b[39m s\u001b[38;5;241m.\u001b[39mp1\u001b[38;5;241m.\u001b[39mx, s\u001b[38;5;241m.\u001b[39mp2\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m-\u001b[39m s\u001b[38;5;241m.\u001b[39mp1\u001b[38;5;241m.\u001b[39my])\n\u001b[0;32m      8\u001b[0m v1, v2 \u001b[38;5;241m=\u001b[39m vec(s1), vec(s2)\n\u001b[0;32m      9\u001b[0m ang \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marccos(\n\u001b[1;32m---> 10\u001b[0m     np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39mdot(v1, v2) \u001b[38;5;241m/\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(v2)), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m mid1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(s1\u001b[38;5;241m.\u001b[39mp1\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m+\u001b[39m s1\u001b[38;5;241m.\u001b[39mp2\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, (s1\u001b[38;5;241m.\u001b[39mp1\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m+\u001b[39m s1\u001b[38;5;241m.\u001b[39mp2\u001b[38;5;241m.\u001b[39my) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     14\u001b[0m mid2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(s2\u001b[38;5;241m.\u001b[39mp1\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m+\u001b[39m s2\u001b[38;5;241m.\u001b[39mp2\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, (s2\u001b[38;5;241m.\u001b[39mp1\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m+\u001b[39m s2\u001b[38;5;241m.\u001b[39mp2\u001b[38;5;241m.\u001b[39my) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\rapids-23.12\\lib\\site-packages\\numpy\\linalg\\_linalg.py:2744\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2742\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x_real\u001b[38;5;241m.\u001b[39mdot(x_real) \u001b[38;5;241m+\u001b[39m x_imag\u001b[38;5;241m.\u001b[39mdot(x_imag)\n\u001b[0;32m   2743\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2744\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2745\u001b[0m ret \u001b[38;5;241m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segments = extract_segments(df_chunk)\n",
    "\n",
    "labels = cluster_segments(\n",
    "    segments=segments,\n",
    "    eps=0.02,\n",
    "    min_samples=5\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
